{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5067d-ce4a-4635-a1b8-45435f434498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn' or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8af8b2-fe4c-4d7a-bf6c-480bba12ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to set up the folder variables for where to read and write data. Since the dataset is gigantic the downloading was done\n",
    "# outside of Python.\n",
    "\n",
    "dataset_folder = r'C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\DREAMT\\dataset'\n",
    "\n",
    "grouped_data_folder = dataset_folder + '\\\\grouped_100Hz'\n",
    "clean_data_folder = dataset_folder + '\\\\clean_data'\n",
    "\n",
    "if not os.path.exists(grouped_data_folder):\n",
    "    os.makedirs(grouped_data_folder)\n",
    "\n",
    "if not os.path.exists(clean_data_folder):\n",
    "    os.makedirs(clean_data_folder)\n",
    "\n",
    "df_participants = pd.read_csv(f'{dataset_folder}\\\\participant_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0d206-e635-418b-8fdf-052eb4d934ae",
   "metadata": {},
   "source": [
    "Custom Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cce54-3347-425b-9831-0280c8f7b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# For more readability, we define and use a function to format all our column names and string entries such that \n",
    "# they're properly and consistently capitalized. This function does not affect all-uppercase words as the majority of these are medical acronyms\n",
    "def format_text(text):\n",
    "    text = text.replace('_', ' ')\n",
    "    temp_text = ''\n",
    "    for i, letter in enumerate(text):\n",
    "        if i == 0 or text[i-1] == ' ':\n",
    "            temp_text = temp_text + letter.capitalize()\n",
    "        else:\n",
    "            temp_text = temp_text + letter\n",
    "    return temp_text\n",
    "##################################################\n",
    "# Function to iterate format_text on every column name\n",
    "def format_cols(df):\n",
    "    return df.rename(mapper=format_text, axis='columns')\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc683093-f67b-4e56-9971-bf1e4b682fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "def table_stack(df, id_col, col_name):\n",
    "# This function is a simple stacking task to help automate the compression of a multitude of boolean columns into one column that counts the occurence of\n",
    "# that column alongside the index column. This is much more effective than storing dozens of boolean columns, as we have a lot of rows that have only one\n",
    "# boolean value and a ton of redundant Falses.\n",
    "\n",
    "    df_temp = df.set_index(id_col).stack().reset_index()\n",
    "    \n",
    "    df_temp.columns = [id_col, col_name, 'bool_val_tmp']\n",
    "    \n",
    "    df_stacked = df_temp[df_temp['bool_val_tmp']==1]\n",
    "    \n",
    "    return df_stacked.drop(labels='bool_val_tmp', axis=1)\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d356f-eec7-4d65-b444-a745d40d1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The participants info CSV file has two problematic columns: MEDICAL_HISTORY and Sleep_Disorders. These columns store info regarding patients\n",
    "# in a string format, where certain conditions show up separated by commas. This makes the data annoying to work with in external programs, so\n",
    "# we define a function to separate these string columns into boolean columns using a function.\n",
    "# These functions are imported from a previous portfolio project, Stack Overflow 2022-2024 Surveys Analysis, which can be found in the below Github link:\n",
    "\n",
    "# https://github.com/MustafaBerkPolat/so22-24survey\n",
    "\n",
    "##################################################\n",
    "def split_string_checklist(df, column_name, separator=';', identifier='null'):\n",
    "# This function takes a string column of a dataframe and splits this column into multiple boolean columns based on\n",
    "# the occurence of a separator character, most typically a semicolon, and outputs a new dataframe containing these new\n",
    "# bool columns\n",
    "# The identifier input, if not left to its default value of 'null', adds a prefix before the column names to help identify shared column\n",
    "# names between dataframes\n",
    "\n",
    "# Making array from columns and discarding repeat entries to make it easier to work with\n",
    "    arr = df[column_name].unique()\n",
    "\n",
    "# Splitting values and making nested list with them\n",
    "    nested_lists = [str(i).split(separator) for i in arr]\n",
    "\n",
    "\n",
    "# Getting all the unique values from list (getting the new column names)\n",
    "    split_values = set()\n",
    "    \n",
    "    for sublist in nested_lists:\n",
    "        split_values.update(sublist)\n",
    "    split_values = sorted(split_values)\n",
    "\n",
    "    \n",
    "# Making new df with boolean, isinstance to avoid null/nan values\n",
    "    new_df = pd.DataFrame(df[column_name])\n",
    "    for column in split_values:\n",
    "        new_df[column] = df[column_name].apply(\n",
    "            lambda x: column in x if isinstance(x, (list, str)) else False).astype(int)\n",
    "\n",
    "    \n",
    "# Replacing null values with True bool and non-null values with False bool for selected column for future analysis\n",
    "    df_temp = pd.DataFrame(df)\n",
    "    df_temp[column_name] = df_temp[column_name].apply(lambda x: True if pd.isnull(x) else False)\n",
    "\n",
    "    \n",
    "# Combining 'duplicate' columns with different notations into one column, since not every name is consistently formatted across years\n",
    "# eg. 'Couch DB' is spelled as 'CouchDB' in one year\n",
    "    simple_names = []\n",
    "    names= []\n",
    "\n",
    "    for col in split_values:\n",
    "        names.append(col)\n",
    "        simple_names.append(col.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").lower())\n",
    "\n",
    "    \n",
    "    pairs = []\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        pairs.append([name, names[simple_names.index(simple_names[i])]])\n",
    "\n",
    "    \n",
    "    for col in pairs:\n",
    "        if col[0] != col[1]:\n",
    "            new_df[col[1]] = new_df[[col[0], col[1]]].any(axis=1).astype(int)\n",
    "\n",
    "# Dropping the now unnecessary duplicate columns, and renaming the remaining column to include the optional identifier string\n",
    "# at the start of the column names. This is useful as multiple dataframes can have columns that have the same name but represent\n",
    "# different things\n",
    "    for col in pairs:\n",
    "        if col[0] != col[1]:\n",
    "            if col[0] in new_df.columns:\n",
    "                new_df.drop(col[0], axis=1, inplace=True)\n",
    "        else:\n",
    "            if identifier != 'null':\n",
    "                new_col = identifier + '-' + col[1]\n",
    "                new_df[new_col] = new_df[col[1]]\n",
    "                new_df.drop(col[1], axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "# Combining new df with old one\n",
    "    df_combined = pd.concat([df_temp*1, new_df], axis=1)\n",
    "    df_combined.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "    if 'nan' in df_combined.columns:\n",
    "        df_combined.drop('nan', axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    return df_combined\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e9517-801a-48e5-8360-9ccdff167adb",
   "metadata": {},
   "source": [
    "Aggregating the measured data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df920d47-1829-4acb-9204-7b6f131da450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw data we have totals to over 3 billion rows and 30 columns, so it needs to be aggregated to be workable first. Since the data has sleep stage\n",
    "# tracking, doing this aggregation by grouping by both participant and sleep stage is the most handy aggregation we can calculate\n",
    "\n",
    "files_list_raw = os.listdir(dataset_folder + '\\\\data_100Hz')\n",
    "# files_list_raw = ['S002_PSG_df.csv']\n",
    "\n",
    "# The aggregate functions we will be calculating. We calculate the minimum and maximum for the variable measurements, but for the columns that track\n",
    "# whether an event has occurred or not, tracking these values is pointless and can be replaced by the sum of these incidents instead.\n",
    "aggs = ['mean', 'std', 'min', 'max']\n",
    "counts = ['mean', 'std', 'sum']\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    "    'C4-M1': aggs,\n",
    "    'F4-M1': aggs,\n",
    "    'O2-M1': aggs,\n",
    "    'Fp1-O2': aggs,\n",
    "    'T3 - CZ': aggs,\n",
    "    'CZ - T4': aggs,\n",
    "    'CHIN': aggs,\n",
    "    'E1': aggs,\n",
    "    'E2': aggs,\n",
    "    'ECG': aggs,\n",
    "    'LAT': aggs,\n",
    "    'RAT': aggs,\n",
    "    'SNORE': aggs,\n",
    "    'PTAF': aggs,\n",
    "    'FLOW': aggs,\n",
    "    'THORAX': aggs,\n",
    "    'ABDOMEN': aggs,\n",
    "    'SAO2': aggs,\n",
    "    'BVP': aggs,\n",
    "    'ACC_X': aggs,\n",
    "    'ACC_Y': aggs,\n",
    "    'ACC_Z': aggs,\n",
    "    'TEMP': aggs,\n",
    "    'EDA': aggs,\n",
    "    'HR': aggs,\n",
    "    'IBI': aggs,\n",
    "    'Obstructive_Apnea': counts,\n",
    "    'Central_Apnea': counts,\n",
    "    'Hypopnea': counts\n",
    "}\n",
    "\n",
    "\n",
    "# Defining the dataframe that'll contain the aggregated info\n",
    "df_aggregate = pd.DataFrame()\n",
    "\n",
    "########################################################\n",
    "\n",
    "for index, file in enumerate(files_list_raw):\n",
    "    df_temp = pd.read_csv(f'{dataset_folder}\\\\data_100Hz\\\\{file}')\n",
    "    \n",
    "########################################################\n",
    "    \n",
    "    # We create a separate copy of the read dataframe to perform a separate aggregation operation on. This uses more memory but is much faster than\n",
    "    # reading the file twice in my system, and allows us to calculate the duration of each sleep stage more easily to then append to our main\n",
    "    # aggregated dataframe.\n",
    "    df_temp_duration = df_temp[['TIMESTAMP', 'Sleep_Stage']]\n",
    "\n",
    "    \n",
    "    # Reading the SID column of the participant info CSV to append to the aggregate measurements data\n",
    "    df_temp_duration['SID'] = df_participants.iloc[index,0]\n",
    "\n",
    "\n",
    "    # Calculating the individual sleep stages. We can't simply use groupby since these sleep stages repeat throughout the night with other stages\n",
    "    # interspersed between them, and we want to account for these separations and treat each repetition of a stage separately for aggregation\n",
    "    df_temp_duration['Stage_Number'] = (df_temp_duration['Sleep_Stage'] != df_temp_duration['Sleep_Stage'].shift()).cumsum()\n",
    "\n",
    "\n",
    "    # Calculating how long each sleep stage is\n",
    "    duration = df_temp_duration.groupby('Stage_Number')['TIMESTAMP'].apply(lambda x: x.max() - x.min())\n",
    "\n",
    "\n",
    "    # Grouping by the stage number value to then assign the stage duration parameters for\n",
    "    df_temp_duration = df_temp_duration.groupby('Stage_Number').agg({\n",
    "        'TIMESTAMP': 'std',\n",
    "        'Sleep_Stage': lambda x: x.mode()[0]\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Breaking the multi-index structure and renaming the columns\n",
    "    # df_temp_duration.rename(columns={'Sleep Stage <lambda>': 'Sleep Stage'}, inplace=True)\n",
    "\n",
    "    \n",
    "    # Defining the Stage_Duration column with our previous calculations\n",
    "    df_temp_duration['Stage_Duration'] = duration.values\n",
    "\n",
    "\n",
    "    # Aggregating the stage duration per different kind of sleep stage and counting how many times each stage occurs\n",
    "    df_temp_duration = df_temp_duration.groupby('Sleep_Stage').agg({\n",
    "        'Stage_Duration': aggs,\n",
    "        'Sleep_Stage': 'count'})\n",
    "\n",
    "    # Flattening the MultiIndex columns to be exportable\n",
    "    df_temp_duration.columns = ['_'.join(col).strip() if col[1] else col[0] for col in df_temp_duration.columns.values]\n",
    "\n",
    "########################################################\n",
    "    \n",
    "    # Then we move on to aggregating the actual measured information like heart rate and electrodermal activity. \n",
    "    df_temp = df_temp.fillna(0).groupby('Sleep_Stage').agg(agg_funcs)\n",
    "\n",
    "    \n",
    "    # Flattening the MultiIndex columns to be exportable\n",
    "    df_temp.columns = ['_'.join(col).strip() if col[1] else col[0] for col in df_temp.columns.values]\n",
    "\n",
    "\n",
    "    # Merging the two dataframes together\n",
    "    df_temp = pd.merge(df_temp, df_temp_duration, on='Sleep_Stage', how='outer')\n",
    "\n",
    "\n",
    "    # Reading the SID column of the participant info CSV to append to the aggregate measurements data\n",
    "    df_temp['SID'] = df_participants.iloc[index,0]\n",
    "\n",
    "\n",
    "    # Appending the merged dataframes back into the main aggregate dataframe\n",
    "    df_aggregate = pd.concat([df_aggregate, df_temp])\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0e4da-0ff8-4c42-aef9-eab5761a5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate.reset_index(drop=False, inplace=True)\n",
    "\n",
    "\n",
    "# Reordering columns for clarity\n",
    "df_aggregate = df_aggregate[['SID', 'Sleep_Stage'] + [col for col in df_aggregate.columns if col not in ['SID', 'Sleep_Stage']]]\n",
    "\n",
    "\n",
    "# Formatting the columns to be more readable. This function leaves some of the measurement data as capitalized (like THORAX and CHIN) but\n",
    "# this distinction makes it easier to differentiate between measurements and similarly named conditions so it is not worth it to try and rename them\n",
    "# in this case\n",
    "df_aggregate = format_cols(df_aggregate)\n",
    "\n",
    "\n",
    "# Renaming the columns with redundant spaces to get rid of these spaces so that they're easier to format alongside our other columns\n",
    "# when visualizing\n",
    "df_aggregate.rename(columns={\n",
    "     'T3 - CZ Mean': 'T3-CZ Mean',\n",
    "     'T3 - CZ Std': 'T3-CZ Std',\n",
    "     'T3 - CZ Min': 'T3-CZ Min',\n",
    "     'T3 - CZ Max': 'T3-CZ Max',\n",
    "     'CZ - T4 Mean': 'CZ-T4 Mean',\n",
    "     'CZ - T4 Std': 'CZ-T4 Std',\n",
    "     'CZ - T4 Min': 'CZ-T4 Min',\n",
    "     'CZ - T4 Max': 'CZ-T4 Max'}, inplace=True)\n",
    "\n",
    "\n",
    "# Saving the file\n",
    "df_aggregate.to_csv(f'{clean_data_folder}\\\\df_aggregate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db4c2a-9e4b-4bff-a816-68d5308a2c40",
   "metadata": {},
   "source": [
    "Cleaning the participant info CSV and creating pivot-table style CSV files for the medical history and sleep condition data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeecb12-815f-4b1d-864b-0bb3556ce208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By assigning an identifier to separate the end results of the splitting of two columns, we ensure there is no confusion regarding\n",
    "# where each column comes from. This is needed as conditions like 'sleep apnea' can show up in both and knowing which column the data\n",
    "# came from is important as the Sleep_Disorder column tracks the researchers' observation during the experiment, while MEDICAL_HISTORY\n",
    "# represents past diagnoses.\n",
    "\n",
    "df_medical_history = split_string_checklist(df_participants, 'MEDICAL_HISTORY', separator=', ')\n",
    "df_sleep_disorders = split_string_checklist(df_participants, 'Sleep_Disorders', separator=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b36873-f3a6-4383-afb1-72900aab912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining 'grinds teeth' and 'grind teeth' under 'bruxism', the scientific term for teeth grinding\n",
    "df_sleep_disorders['bruxism'] = df_sleep_disorders[['grinds teeth', 'grind teeth', 'bruxism']].any(axis='columns').astype(int)\n",
    "\n",
    "df_sleep_disorders.drop(labels=['grind teeth', 'grinds teeth'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 'fatigue' and 'chronic fatigue' columns under 'chronic fatigue'\n",
    "df_sleep_disorders['Chronic fatigue'] = df_sleep_disorders[['fatigue', 'Chronic fatigue']].any(axis='columns').astype(int)\n",
    "\n",
    "df_sleep_disorders.drop(labels='fatigue', axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Dismantling the 'OSA snoring' column into the 'OSA' and 'Snoring' columns, also combining 'Snoring' and 'snore\n",
    "df_sleep_disorders['OSA'] = df_sleep_disorders[['OSA', 'OSA snoring']].any(axis='columns').astype(int)\n",
    "df_sleep_disorders['Snoring'] = df_sleep_disorders[['Snoring', 'OSA snoring', 'snore']].any(axis='columns').astype(int)\n",
    "\n",
    "df_sleep_disorders.drop(labels=['OSA snoring', 'snore'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 'diffifulty breathing' column into the one without typos\n",
    "df_sleep_disorders['difficulty breathing'] = df_sleep_disorders[['difficulty breathing', 'diffifulty breathing']].any(axis='columns').astype(int)\n",
    "\n",
    "df_sleep_disorders.drop(labels='diffifulty breathing', axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Combining 'snort' and 'snorts'\n",
    "df_sleep_disorders['snort'] = df_sleep_disorders[['snort', 'snorts']].any(axis='columns').astype(int)\n",
    "\n",
    "df_sleep_disorders.drop(labels='snorts', axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Combining all the different variations of sleep apnea under one sleep disorder column, and splitting the 'MCI and sleep apnea' column into its own\n",
    "# MCI column. Everyone in this research who was reported to have major cognitive impairment also had sleep apnea, so we can just \n",
    "# rename the existing column into MCI and include everyone in it in our sleep apnea column as well without problem\n",
    "df_sleep_disorders['Sleep apnea'] = df_sleep_disorders[[\n",
    "    'MCI and Sleep apnea',\n",
    "    'OSA', \n",
    "    'H/O OSA',\n",
    "    'Sleep apnea']].any(axis='columns').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_sleep_disorders.drop(labels=['OSA', 'H/O OSA'], axis='columns', inplace=True)\n",
    "df_sleep_disorders.rename(columns={'MCI and Sleep apnea': 'MCI'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Since 'Sleep Apnea' is present in both the sleep disorders and medical history dataframes, we need to either rename one and keep both, or\n",
    "# combine the two after merging the dataframes back into our participants frame. In this case, I opted for renaming the sleep disorders entry to\n",
    "# 'Sleep Apnea (Observed)'\n",
    "df_sleep_disorders.rename(columns={'Sleep apnea': 'Sleep Apnea (Observed)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55292f80-3a2e-4f79-80f9-6b81058492cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop the columns that correspond to no as a response as well as the columns that contain non-boolean data that will be\n",
    "# stored in a separate CSV file\n",
    "df_sleep_disorders.drop(labels=['AGE', 'GENDER', 'BMI', 'OAHI', 'AHI', 'Mean_SaO2',  'Arousal Index', 'MEDICAL_HISTORY', 'none'], axis='columns', inplace=True)\n",
    "\n",
    "df_medical_history.drop(labels=['AGE', 'GENDER', 'BMI', 'OAHI', 'AHI', 'Mean_SaO2',  'Arousal Index', 'Sleep_Disorders'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "# Formatting the datasets to be more readable with our format_cols function\n",
    "df_sleep_disorders = format_cols(df_sleep_disorders)\n",
    "df_medical_history = format_cols(df_medical_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd4296-da1b-4636-866c-0aece5363542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the participants and grouped dataframe has some columns that make sense to be capitalized (BMI, OAHI, SID etc.) and others that don't \n",
    "# (AGE and GENDER), it makes sense to do manual work here as opposed to working out the edge cases of our functions\n",
    "df_participants.rename(columns={\n",
    "    'AGE': 'Age', \n",
    "    'GENDER': 'Gender',\n",
    "    'Mean_SaO2': 'Mean SaO2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3446ff4-2fb3-4653-9b5a-73a3b3068fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we stack the boolean columns back together to have a pivot table-style CSV file for the sleep disorder and medical history info.\n",
    "# Before this stacking, we can also re-merge the boolean columns into our participants info table, just so we have the data in the\n",
    "# boolean columns format as well, in case this format is easier to use in our analysis program than the pivot table-style.\n",
    "\n",
    "# Dropping the hard-to-work-with string columns\n",
    "df_participants.drop(labels=['MEDICAL_HISTORY', 'Sleep_Disorders'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "# Merging the boolean sleep disorder and medical history dataframes together to then merge with the participant info\n",
    "df_temp = pd.merge(df_sleep_disorders, df_medical_history, on='SID', how='outer')\n",
    "df_participants = pd.merge(df_participants, df_temp, on='SID', how='outer')\n",
    "\n",
    "\n",
    "# Stacking the sleep disorder and medical history dataframes into the pivot table format\n",
    "df_sleep_disorders = table_stack(df_sleep_disorders, 'SID', 'Sleep Disorders')\n",
    "df_medical_history = table_stack(df_medical_history, 'SID', 'Medical History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ac9a1-17f6-4917-89b3-59f1289cd47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the three dataframes\n",
    "df_participants.to_csv(f'{clean_data_folder}\\\\df_participants.csv', index=False)\n",
    "\n",
    "df_sleep_disorders.to_csv(f'{clean_data_folder}\\\\df_sleep_disorders.csv', index=False)\n",
    "\n",
    "df_medical_history.to_csv(f'{clean_data_folder}\\\\df_medical_history.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
